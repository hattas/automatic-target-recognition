{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from csvs\n",
    "df_features = pd.read_csv('../csvs/features.csv',index_col=0)\n",
    "df_regional = pd.read_csv('../csvs/regional_features.csv',index_col=0)\n",
    "\n",
    "# concatenate the two df's together\n",
    "df_regional.drop(['file','label'],axis=1,inplace=True)\n",
    "df = pd.concat([df_features, df_regional], axis=1)\n",
    "\n",
    "# drop values with null labels (blind testing data)\n",
    "df_dropna = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (data) (1005, 119) <class 'numpy.ndarray'>\n",
      "y (target) (1005,) <class 'numpy.ndarray'> [0. 1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "X = df_dropna.drop(['file','label'],axis=1).values\n",
    "y = df_dropna.label.values\n",
    "\n",
    "print('X (data)',X.shape,type(X))\n",
    "print('y (target)',y.shape,type(y),np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcc(y_true,y_pred):\n",
    "    return accuracy_score(y_true,y_pred)\n",
    "\n",
    "def getPD(y_true,y_pred):\n",
    "    '''get percent detected (# targets detected / # targets)'''\n",
    "    return recall_score(y_true,y_pred)\n",
    "\n",
    "def getPFA(y_true,y_pred):\n",
    "    '''get percent false alarms (# false alarms / # non-targets)'''\n",
    "    return 1-accuracy_score(1-y_true,1-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "kf = KFold(n_splits=5)\n",
    "PD,PD1,PD2,PD3 = [],[],[],[]\n",
    "PFA = []\n",
    "acc1,acc2,acc3=[],[],[]\n",
    "acc_mult,acc_mult_to_bin,acc_bin,acc_comb = [],[],[],[]\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "    predict_mult = clf.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    predict_mult_to_bin = predict_mult!=0\n",
    "    \n",
    "    predict_bin = clf.fit(X_train, y_train!=0).predict(X_test)\n",
    "    \n",
    "    predict1 = clf.fit(X_train, y_train==1).predict(X_test)\n",
    "    predict2 = clf.fit(X_train, y_train==2).predict(X_test)\n",
    "    predict3 = clf.fit(X_train, y_train==3).predict(X_test)\n",
    "    \n",
    "    predict_target = np.logical_or.reduce((predict1, predict2, predict3))\n",
    "    \n",
    "    acc_mult.append(getAcc(y_test, predict_mult))\n",
    "    acc_mult_to_bin.append(getAcc(y_test!=0, predict_mult_to_bin))\n",
    "    acc_bin.append(getAcc(y_test!=0, predict_bin))\n",
    "    acc_comb.append(getAcc(y_test!=0, predict_target))\n",
    "    acc1.append(getAcc(y_test==1, predict1))\n",
    "    acc2.append(getAcc(y_test==2, predict2))\n",
    "    acc3.append(getAcc(y_test==3, predict3))\n",
    "    PD.append(getPD(y_test!=0, predict_bin))\n",
    "    PD1.append(getPD(y_test==1, predict_bin))\n",
    "    PD2.append(getPD(y_test==2, predict_bin))\n",
    "    PD3.append(getPD(y_test==3, predict_bin))\n",
    "    PFA.append(getPFA(y_test!=0, predict_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy mult           0.709452736318408\n",
      "accuracy mult to bin    0.25870646766169153\n",
      "accuracy bin            0.8477611940298507\n",
      "accuracy comb           0.8497512437810946\n",
      "accuracy saline only    0.9343283582089551\n",
      "accuracy rubber only    0.9462686567164178\n",
      "accuracy clay only      0.9592039800995025\n",
      "percent detected        0.741113102076752\n",
      "percent detected saline 0.706047619047619\n",
      "percent detected rubber 0.7672772191023465\n",
      "percent detected clay  0.7472588522588524\n",
      "percent false alarm     0.15223880597014922\n"
     ]
    }
   ],
   "source": [
    "print('accuracy mult          ',np.mean(acc_mult))\n",
    "print('accuracy mult to bin   ',np.mean(predict_mult_to_bin))\n",
    "print('accuracy bin           ',np.mean(acc_bin))\n",
    "print('accuracy comb          ',np.mean(acc_comb))\n",
    "print('accuracy saline only   ',np.mean(acc1))\n",
    "print('accuracy rubber only   ',np.mean(acc2))\n",
    "print('accuracy clay only     ',np.mean(acc3))\n",
    "print('percent detected       ',np.mean(PD))\n",
    "print('percent detected saline',np.mean(PD1))\n",
    "print('percent detected rubber',np.mean(PD2))\n",
    "print('percent detected clay ' ,np.mean(PD3))\n",
    "print('percent false alarm    ',np.mean(PFA))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
